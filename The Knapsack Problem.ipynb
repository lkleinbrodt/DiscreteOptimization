{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.5 64-bit ('PSS': conda)"
  },
  "interpreter": {
   "hash": "af409aec82340d0669463323393db2ed8f39f0c33bf641bb1029a7c6c279d84e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "# Dynamic Programming\n",
    "\n",
    " - Divide and Conquer\n",
    " - Bottom up computation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Recurrence Relations (Bellman Equations)\n",
    "\n",
    "We have our napsack problem with n items, I=[1,...,n]\n",
    "\n",
    "We will split it up. Define a function O(k,j) which represents the optimal solution value for items [1,...,j] (subset of all items)\n",
    "\n",
    "Now: \n",
    "\n",
    "Assume we know how to solve O(k, j-1) for all k in 0...K\n",
    "\n",
    "We now want to solve O(k,j), we're just considering ONE more items\n",
    "\n",
    "if w_j < k, (the item fits in the napsack) there are two cases\n",
    " - We do NOT select th item, then the best solution is still O(k, j-1)\n",
    " - We DO select the item, and then the best selection is v_j + O(k-w_j, j-1)\n",
    "\n",
    "So: \n",
    "- O(k,j) = max(O(k, j-1), v_j + O(k-w_j, j-w)) if w_j <k\n",
    "- other O9k,j) = O(k, j-1) if doesnt fits\n",
    "\n",
    "and the base case is a napsack with 0 weight, nothing vits, value = 0\n",
    "\n",
    "Is this algorithm efficient though?\n",
    "\n",
    "let's test it on fibonacci numbers"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "if (n == 0) | (n == 1):\n",
    "    return 1\n",
    "else:\n",
    "    return fib(n-2) + fib(n-1)\n",
    "\n",
    "We are solving many times in the same subproblem. Tons of duplication, super inefficient\n",
    "    But that's cause this is top down. what if we did it button up??? Start with 0 then go up"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "[/Users/lndk/Desktop/Screenshots/dynamic\\ prog\\ table.png]"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Branch and Bound\n",
    "\n",
    "and the value of relaxation\n",
    "\n",
    "We've talked about how brute force would take too long due to permutations, but we can do a branching, and then search only a tiny fraction of the entire tree.\n",
    "\n",
    "Iterative 2 steps:\n",
    "- Branching: split problem into a number of subproblems\n",
    "- Bounding: find an **optimistic estimate** of the best solution to the sub-problem\n",
    "\n",
    "how to find the optimistic estimate? RELAXATION\n",
    "- Optimization is the art of relaxation\n",
    "\n",
    "In the napsack, what can we relax?\n",
    " - the capacity constraint. Assume you can put all *available* items into the sack (just to do your optimistic evaluation)\n",
    " - When your optimistic evaluation is lower than your best solution so far, you dont have to explore the rest of that tree\n",
    "\n",
    "The better your relaxation (the more you can prune your tree) the better\n",
    "\n",
    "What else can we relax?\n",
    " - What if the items are bars of Belgian chocolate? we can take a FRACTION of the bar!!!\n",
    " - This is the **linear relaxation**. We'll come back to it. We relax the *integrality requirement* \n",
    "\n",
    "Order items by decreasing Value per Weight. Then select all items until capacity is exhausted, then the next fraction, to fill the napsack. This is a better relaxation than before, \n",
    "\n",
    "### Search Strategies\n",
    "\n",
    "- Depth First: prunes when a node estimation is worse than the best found solution\n",
    "- Best First: select the node with the best estimation (aka breadth first?)\n",
    "- Least Discrepency: trust a greedy heuristic\n",
    "\n",
    "Depth First:\n",
    "- When does it prune? when it findsa. new node worse than the found solution?\n",
    "- Is it memory efficient? Well the most nodes you'll need to remember is just one full branch, which is all the items, so yeah it's efficient\n",
    "\n",
    "Best First:\n",
    "- When does it prune? when all nodes are worse than a found solution.\n",
    "- If your estimation is always super high, you'll have to expand all the nodes. so you'll store the entire tree, 2^i. Not gonna work.\n",
    "- When is best first really good? When your estimator is perfect. then you'll select the minimal amount of nodes.\n",
    "\n",
    "Limited Discrepancy Search\n",
    "- Assume you have a good heuristic, makes very few mistakes.\n",
    "- Assume search tree is binary. Following the heuristic means branching left, so branching right means the heuristic was wrong.\n",
    "\n",
    "In this, we try to avoid mistakes. Explor the search space in increasing order of mistakes, trusting the heuristic less and less.\n",
    "\n",
    "Wave 1 you make no mistakes, then you make one \"mistake\", then two, then three, etc.\n",
    "\n",
    "What's cool is that in this way you'll be exploring all over the tree very quickly, rather than in depth first, where you go \"from left to right\"\n",
    "\n",
    "- Is it memory efficient? Depending on how you implement it, there is a trade off between space and time. It's a gradient."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}